{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyramidNet.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/klinime/Intro_to_CNN/blob/master/PyramidNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMaIO9hWzJwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import glob, csv\n",
        "import time, datetime\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [20, 10]\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asrEfjPw-zV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Credit PyramidNet:     https://arxiv.org/pdf/1610.02915.pdf\n",
        "# Credit DSConv:         https://arxiv.org/pdf/1610.02357.pdf\n",
        "# Credit ShakeDrop:      https://arxiv.org/pdf/1802.02375.pdf\n",
        "# Credit Cutout:         https://arxiv.org/pdf/1708.04552.pdf\n",
        "# Credit Implementation: https://github.com/osmr/imgclsmob/blob/master/pytorch/pytorchcv/models\n",
        "# Credit Implementation: https://github.com/uoguelph-mlrg/Cutout\n",
        "\n",
        "class ShakeDrop(torch.autograd.Function):\n",
        "  @staticmethod\n",
        "  def forward(ctx, x, b, alpha):\n",
        "    y = (b + alpha - b * alpha) * x\n",
        "    ctx.save_for_backward(b)\n",
        "    return y\n",
        "\n",
        "  @staticmethod\n",
        "  def backward(ctx, dy):\n",
        "    beta = torch.rand(dy.size(0), dtype=dy.dtype, device=dy.device).view(-1, 1, 1, 1)\n",
        "    b, = ctx.saved_tensors\n",
        "    return (b + beta - b * beta) * dy, None, None\n",
        "\n",
        "class DSConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, stride):\n",
        "    super(DSConv, self).__init__()\n",
        "    self.depthwise = nn.Conv2d(in_channels, in_channels, 3, stride=stride, \\\n",
        "                               padding=1, groups=in_channels, bias=False)\n",
        "    self.pointwise = nn.Conv2d(in_channels, out_channels, 1, bias=False)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.pointwise(self.depthwise(x))\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "  neck_ratio = 4\n",
        "  \n",
        "  def __init__(self, in_channels, out_channels, stride=1, p=1.0, downsample=None):\n",
        "    super(Bottleneck, self).__init__()\n",
        "    neck_channels = out_channels // Bottleneck.neck_ratio\n",
        "    self.features = nn.Sequential(\n",
        "        nn.BatchNorm2d(in_channels),\n",
        "        nn.Conv2d(in_channels, neck_channels, 1, bias=False), # downsample dim d\n",
        "        nn.BatchNorm2d(neck_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        DSConv(neck_channels, neck_channels, stride), # convolve with small dim\n",
        "        nn.BatchNorm2d(neck_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(neck_channels, out_channels, 1, bias=False), # upsample dim d\n",
        "        nn.BatchNorm2d(out_channels)\n",
        "    )\n",
        "    \n",
        "    self.pad = (0, 0, 0, 0, 0, out_channels - in_channels) # dim d\n",
        "    self.stride = stride\n",
        "    self.shakedrop = ShakeDrop.apply\n",
        "    self.p = p # probability for shakedrop\n",
        "    self.downsample = downsample # dim w x h\n",
        "  \n",
        "  def forward(self, x):\n",
        "    r = self.features(x)\n",
        "    if self.training:\n",
        "      b = torch.bernoulli(torch.full((1,), self.p, dtype=r.dtype, device=r.device))\n",
        "      alpha = torch.empty(x.size(0), dtype=x.dtype, device=x.device).view(-1, 1, 1, 1).uniform_(-1.0, 1.0)\n",
        "      r = self.shakedrop(r, b, alpha)\n",
        "    else:\n",
        "      r = self.p * r\n",
        "    \n",
        "    x = self.downsample(x) if self.downsample else x\n",
        "    x = nn.functional.pad(x, self.pad)\n",
        "    return x + r\n",
        "\n",
        "class PyramidNet(nn.Module):\n",
        "  def __init__(self, num_classes, in_size=(32, 32), in_channels=3,\n",
        "               init_channels=16, alpha=200, model=272):\n",
        "    super(PyramidNet, self).__init__()\n",
        "    self.in_channels = init_channels\n",
        "    self.neck_channels = init_channels\n",
        "    block_count = (model - 2) // 3 # minus init conv + linear, 3 layers per block\n",
        "    group_depth = block_count // 3 # 3 groups in total, 32x32 -> 16x16 -> 8x8\n",
        "    self.add_rate = alpha / block_count # additive increase for bottleneck\n",
        "    final_drop_p = 0.5 # shakedrop p on final layer = 1 - final_drop_p\n",
        "    drop_ps = [1 - (i + 1) / block_count * final_drop_p for i in range(block_count)]\n",
        "    self.features = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, init_channels, 3, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(init_channels),\n",
        "        self._pyr_group(1, drop_ps[:group_depth]),\n",
        "        self._pyr_group(2, drop_ps[group_depth: group_depth*2]),\n",
        "        self._pyr_group(2, drop_ps[group_depth*2:]),\n",
        "        nn.BatchNorm2d(self.in_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.AdaptiveAvgPool2d(1)\n",
        "    )\n",
        "    self.classifier = nn.Linear(self.in_channels, num_classes)\n",
        "    \n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
        "      elif isinstance(m, nn.BatchNorm2d):\n",
        "        m.weight.data.fill_(1)\n",
        "        m.bias.data.zero_()\n",
        "      elif isinstance(m, nn.Linear):\n",
        "        m.bias.data.zero_()\n",
        "  \n",
        "  def _pyr_group(self, stride, ps):\n",
        "    downsample = None if stride == 1 else nn.AvgPool2d(2, stride=stride, ceil_mode=True)\n",
        "    layers = []\n",
        "    self.neck_channels += self.add_rate\n",
        "    layers.append(Bottleneck(self.in_channels, int(round(self.neck_channels)) * Bottleneck.neck_ratio, \n",
        "                             stride=stride, p=ps[0], downsample=downsample))\n",
        "    self.in_channels = int(round(self.neck_channels)) * Bottleneck.neck_ratio\n",
        "    for p in ps[1:]:\n",
        "      self.neck_channels += self.add_rate\n",
        "      layers.append(Bottleneck(self.in_channels, int(round(self.neck_channels)) * Bottleneck.neck_ratio, p=p))\n",
        "      self.in_channels = int(round(self.neck_channels)) * Bottleneck.neck_ratio\n",
        "    return nn.Sequential(*layers)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x.view(x.size(0), -1)\n",
        "    x = self.classifier(torch.squeeze(x))\n",
        "    return x\n",
        "\n",
        "class Cutout():\n",
        "  def __init__(self, n, size):\n",
        "    self.n = n\n",
        "    self.size = size\n",
        "  \n",
        "  def __call__(self, img):\n",
        "    h, w = img.size(1), img.size(2)\n",
        "    mask = np.ones((h, w), np.float32)\n",
        "    for _ in range(self.n):\n",
        "      x, y = np.random.randint(w), np.random.randint(h)\n",
        "      x1 = np.clip(x - self.size // 2, 0, w)\n",
        "      x2 = np.clip(x + self.size // 2, 0, w)\n",
        "      y1 = np.clip(y - self.size // 2, 0, h)\n",
        "      y2 = np.clip(y + self.size // 2, 0, h)\n",
        "      mask[y1: y2, x1: x2] = 0\n",
        "    mask = torch.from_numpy(mask).expand_as(img)\n",
        "    return img * mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfqaCJuPNPYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_count = 10\n",
        "dataset = 'cifar' + str(class_count)\n",
        "if dataset == 'cifar10':\n",
        "  mean = [0.4914, 0.4822, 0.4465]\n",
        "  std = [0.2470, 0.2435, 0.2616]\n",
        "elif dataset == 'cifar100':\n",
        "  mean = [0.5071, 0.4867, 0.4408]\n",
        "  std = [0.2675, 0.2565, 0.2761]\n",
        "else:\n",
        "  raise AttributeError('Invalid Dataset')\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "    Cutout(1, 8)\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "path = '/content/gdrive/My Drive/cifar_cnn/'\n",
        "classes = tuple(next(csv.reader(open(path + dataset + '_classes.csv'))))\n",
        "if dataset == 'cifar10':\n",
        "  train_dataset = torchvision.datasets.CIFAR10(root=path, train=True, transform=train_transform)\n",
        "elif dataset == 'cifar100':\n",
        "  train_dataset = torchvision.datasets.CIFAR100(root=path, train=True, transform=train_transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "\n",
        "if dataset == 'cifar10':\n",
        "  test_dataset = torchvision.datasets.CIFAR10(root=path, train=False, transform=test_transform)\n",
        "elif dataset == 'cifar100':\n",
        "  test_dataset = torchvision.datasets.CIFAR100(root=path, train=False, transform=test_transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "final_test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.benchmark = True\n",
        "model = PyramidNet(class_count).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=5e-5)\n",
        "\n",
        "def save_checkpoint(state, filename=path + dataset + '_checkpoint.pt'):\n",
        "  torch.save(state, filename)\n",
        "\n",
        "def load_checkpoint(model, optimizer, filename=path + dataset + '_checkpoint.pt'):\n",
        "  print('Loading Checkpoint...')\n",
        "  checkpoint = torch.load(filename)\n",
        "  start_epoch = checkpoint['epoch']\n",
        "  model.load_state_dict(checkpoint['state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "  print('Loaded Checkpoint (Epoch {})'.format(start_epoch))\n",
        "  return start_epoch, checkpoint['train_loss'], checkpoint['test_loss'], checkpoint['test_acc']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PZgRnp23A2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load = True\n",
        "num_epochs = 10\n",
        "total_step = len(train_loader)\n",
        "mark = 60\n",
        "start_epoch, train_loss, test_loss, test_acc = load_checkpoint(model, optimizer) if load else (0, [], [], [])\n",
        "\n",
        "print('Start Training...')\n",
        "start = time.time()\n",
        "benchmark = start\n",
        "for e in range(start_epoch, start_epoch + num_epochs):\n",
        "  epoch = e + 1\n",
        "  print('Epoch {}'.format(epoch))\n",
        "  for i, (data, labels) in enumerate(train_loader):\n",
        "    model.train() # training mode\n",
        "    data, labels = data.to(device), labels.to(device)\n",
        "    outputs = model(data)\n",
        "    loss = criterion(outputs, labels)\n",
        "    train_loss.append(loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i + 1) % mark == 0:\n",
        "      delta, benchmark = time.time() - benchmark, time.time()\n",
        "      print('Epoch [{}/{}], Step [{}/{}], Training Loss: {:.4f}, Time: {:.2f}s'\n",
        "            .format(epoch, start_epoch + num_epochs, i + 1, total_step, loss, delta))\n",
        "    \n",
        "    if i % 2:\n",
        "      with torch.no_grad():\n",
        "        model.eval() # eval mode\n",
        "        data, labels = next(iter(test_loader))\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "        outputs = model.forward(data)\n",
        "        loss = criterion(outputs, labels).item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        acc = (predicted == labels).sum().item() / labels.size(0)\n",
        "        test_loss.append(loss)\n",
        "        test_acc.append(acc)\n",
        "      if (i + 1) % mark == 0:\n",
        "        print('Epoch [{}/{}], Step [{}/{}], Validation Loss: {:.4f}, Accuracy: {:.4f}'\n",
        "              .format(epoch, start_epoch + num_epochs, i + 1, total_step, loss, acc))\n",
        "\n",
        "  save_checkpoint({\n",
        "      'epoch': epoch,\n",
        "      'state_dict': model.state_dict(),\n",
        "      'optimizer' : optimizer.state_dict(),\n",
        "      'train_loss': train_loss,\n",
        "      'test_loss': test_loss,\n",
        "      'test_acc': test_acc\n",
        "  })\n",
        "  benchmark = time.time()\n",
        "\n",
        "# Note: avg 78s per 60 batches size 64 on Tesla T4\n",
        "print('Training Completed on {} Epochs, Time Elapsed: {}'\n",
        "      .format(num_epochs, datetime.timedelta(seconds=round(benchmark - start))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MI_8rT1FmBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_index = 0 # initial loss may corrupt average\n",
        "test_index = 30\n",
        "training_moving_avg = pd.DataFrame(data=train_loss[train_index:]).rolling(window=total_step, min_periods=1, center=True).mean().values\n",
        "test_moving_avg = pd.DataFrame(data=test_loss[test_index:]).rolling(window=total_step//2, min_periods=1, center=True).mean().values\n",
        "acc_moving_avg = pd.DataFrame(data=test_acc[test_index:]).rolling(window=total_step//2, min_periods=1, center=True).mean().values\n",
        "ma_max = np.amax([np.amax(training_moving_avg), np.amax(test_moving_avg)])\n",
        "training_moving_avg = training_moving_avg / ma_max\n",
        "test_moving_avg = test_moving_avg / ma_max\n",
        "plt.plot(np.arange(train_index, len(train_loss)), training_moving_avg, label='Training Loss')\n",
        "plt.plot(np.arange(test_index*2, len(train_loss), 2), test_moving_avg, label='Validation Loss')\n",
        "plt.plot(np.arange(test_index*2, len(train_loss), 2), acc_moving_avg, label='Validation Accuracy')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8tTqgoBCkL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Start Testing...')\n",
        "start = time.time()\n",
        "with torch.no_grad():\n",
        "  model.eval() # eval mode\n",
        "  correct, total = 0, 0\n",
        "  predict, actual = [], []\n",
        "  for i, (data, labels) in enumerate(final_test_loader):\n",
        "    if (i+1) % 16 == 0:\n",
        "      print('Time elapsed: {}s'.format(time.time() - start))\n",
        "    data, labels = data.to(device), labels.to(device)\n",
        "    outputs = model(data)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    \n",
        "    total += labels.size(0)\n",
        "    predict.extend(predicted)\n",
        "    actual.extend(labels)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "print('Time elapsed: {:.2f}s'.format(time.time() - start))\n",
        "print('Accuracy on the {:.2f} test images: {}%'.format(total, 100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4zQol8JcBu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pl = [p.cpu().numpy().tolist() for p in predict]\n",
        "gt = [a.cpu().numpy().tolist() for a in actual]\n",
        "\n",
        "# Confusion matrix helpful when visualizing small number of classses\n",
        "predict = pd.Series(pl, name='Predicted')\n",
        "actual = pd.Series(gt, name='Actual')\n",
        "confusion = pd.crosstab(actual, predict)\n",
        "print(confusion)\n",
        "\n",
        "acc_dict = {}\n",
        "for num in range(len(classes)):\n",
        "  acc_dict[classes[num]] = np.sum([p and g for (p, g) in zip(np.array(pl) == np.array(gt), np.array(gt) == num)]) / np.sum(np.array(gt) == num)\n",
        "for class_name, acc in acc_dict.items():\n",
        "# for class_name, acc in sorted(acc_dict.items(), key=lambda kv: kv[1]): # sort by accuracy\n",
        "  print('{}: {}'.format(class_name, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}